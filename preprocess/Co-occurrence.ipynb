{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from pprint import pprint as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Берем заранее составленный список героев (собранный автоматически по рабочему корпусу и вычищенный вручную) \n",
    "# и заменяем пробелы в составных именах на _ чтобы избежать появления связей вида имя-патроним, имя-прозвище и т.д.\n",
    "# (т.е. мы не хотим получить связь Conchobar-Ness из составного имени Conchobar mac Nessa)\n",
    "\n",
    "with open('characterlist.txt', 'r', encoding='utf-8') as cl:\n",
    "    characters = set([line.lower().strip() for line in cl])\n",
    "\n",
    "charDict = {}\n",
    "for char in characters:\n",
    "    charDict[char] = re.sub(r'\\s', r'_', char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151750\n"
     ]
    }
   ],
   "source": [
    "# Проделываем ту же замену во всех текстах рабочего корпуса (уже лемматизированных)\n",
    "# Затем проводим простейшую токенизацию (разбиваем по пробелам) и смотрим объем корпуса в токенах\n",
    "\n",
    "path = 'C:\\\\Users\\\\Oksana\\\\Dropbox\\\\Библиотека\\\\Вышка\\\\OldIrish\\\\texts\\\\ulster\\\\processed\\\\lemmatized'\n",
    "files = [name for name in os.listdir(path) if os.path.isfile(os.path.join(path, name))]\n",
    "terms = []\n",
    "for file in files:\n",
    "    with open(os.path.join(path, file), 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "        for char in characters:\n",
    "            if char in text:\n",
    "                text = re.sub(char, charDict[char], text)\n",
    "        terms += text.split()\n",
    "\n",
    "print(len(terms)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Класс, который будет считать совместную встречаемость имен в окне размером 5\n",
    "\n",
    "class Matcher():\n",
    "    def __init__(self, phrases):\n",
    "        phrase_pattern = \"|\".join(\"(?:{})\".format(phrase) for phrase in phrases)\n",
    "        gap_pattern = r\"\\W+(?:\\w+\\W+){0,5}?\"\n",
    "        full_pattern = \"({0}){1}({0})\".format(phrase_pattern, gap_pattern)\n",
    "\n",
    "        self.regex = re.compile(full_pattern)\n",
    "\n",
    "    def match(self, doc):\n",
    "        return self.regex.findall(doc)\n",
    "\n",
    "matcher = Matcher(charDict.values())\n",
    "com = defaultdict(lambda: defaultdict(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Фильтруем результаты и делаем матрицу совместной встречаемости\n",
    "\n",
    "matches = matcher.match(' '.join(terms))\n",
    "filteredMatches = []\n",
    "for el in matches:\n",
    "    el = [name for name in el if len(name) != 0]\n",
    "    el = [name for name in el if el[0] != el[1]]\n",
    "    filteredMatches.append(tuple(set(el)))\n",
    "\n",
    "counts = Counter(filteredMatches)\n",
    "\n",
    "for k, v in counts.items():\n",
    "    if len(k) != 0:\n",
    "        com[k[0]][k[1]] += v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Записываем ее в файл на будущее\n",
    "\n",
    "with open('pair_counts_5.json', 'w', encoding='utf-8') as p:\n",
    "    json.dump(com, p, sort_keys=True, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Привели имена в файле обратно в красивый вид в Notepad++ (так быстрее), вернули капитализацию, так что заново его прочитаем\n",
    "\n",
    "with open('pair_counts_5.json', 'r', encoding='utf-8') as f:\n",
    "    characters = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Cellach': 1,\n",
      " 'Cet': 1,\n",
      " 'Erc': 1,\n",
      " 'Leborcham': 7,\n",
      " 'Lóeg': 1,\n",
      " 'Macha': 1,\n",
      " 'Nem': 2,\n",
      " 'Uisliu': 1}\n"
     ]
    }
   ],
   "source": [
    "pp(characters['Deirdriu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Осталось превратить все это в граф\n",
    "\n",
    "import networkx as nx\n",
    "G=nx.Graph()\n",
    "\n",
    "for k, v in characters.items():\n",
    "    for link, weight in v.items():\n",
    "        G.add_weighted_edges_from([(k, link, weight)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Ailill, Cú Roí, 14)\n",
      "(Ailill, Medb, 133)\n",
      "(Ailill, Sencha, 19)\n",
      "(Ailill, Fergus, 54)\n",
      "(Ailill, Cú Culand, 13)\n",
      "(Lóegaire, Conall, 12)\n",
      "(Cú Culand, Conchobar, 14)\n",
      "(Cú Culand, Ailill, 13)\n",
      "(Cú Culand, Medb, 25)\n",
      "(Cú Culand, Láeg, 24)\n",
      "(Cú Culand, Fergus, 33)\n",
      "(Cormac, Conchobar, 17)\n",
      "(Sencha, Ailill, 19)\n",
      "(Medb, Conchobar, 12)\n",
      "(Medb, Ailill, 133)\n",
      "(Medb, Cú Culand, 25)\n",
      "(Medb, Fergus, 36)\n",
      "(Fíngen, Cethern, 14)\n",
      "(Conchobar, Cathbad, 14)\n",
      "(Conchobar, Fergus, 20)\n",
      "(Conchobar, Medb, 12)\n",
      "(Conchobar, Cú Culand, 14)\n",
      "(Conchobar, Cormac, 17)\n",
      "(Cethern, Fíngen, 14)\n",
      "(Fergus, Ailill, 54)\n",
      "(Fergus, Medb, 36)\n",
      "(Fergus, Conchobar, 20)\n",
      "(Fergus, Cú Culand, 33)\n",
      "(Láeg, Cú Culand, 24)\n",
      "(Cú Roí, Ailill, 14)\n",
      "(Cathbad, Conchobar, 14)\n",
      "(Conall, Lóegaire, 12)\n"
     ]
    }
   ],
   "source": [
    "# Проверяем, что получилось (смотрим самые сильные связи)\n",
    "\n",
    "for n,nbrs in G.adjacency_iter():\n",
    "    for nbr,eattr in nbrs.items():\n",
    "        data=eattr['weight']\n",
    "        if data > 10:\n",
    "            print('(%s, %s, %d)' % (n,nbr,data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Осталось только экспортировать в формат, поддерживаемый Gephi, чтобы потом экспортировать в Sigma\n",
    "\n",
    "nx.write_graphml(G, 'Ulster.graphml', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ":0: FutureWarning: IPython widgets are experimental and may change in the future.\n"
     ]
    }
   ],
   "source": [
    "# Попробуем нарисовать\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "\n",
    "nx.draw_random(G)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cellach', 'Leborcham', 'Lóeg', 'Cet', 'Nem', 'Macha', 'Erc', 'Uisliu']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.neighbors('Deirdriu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
